{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kajalwasnik/Credit-card-default-predictions/blob/main/Credit_card_default_predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Credit Card Default**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "\n",
        "**Name** - Kajal Wasnik"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The aim of this project was to analyze a dataset on credit card defaults and develop a predictive model to identify potential defaulters. The dataset included information about credit card holders, covering demographics, credit card usage patterns, and payment history.\n",
        "\n",
        "The initial steps involved data exploration, cleaning, and organization. This included renaming columns (e.g., changing PAY_0 to PAY_1 and Is_defaulter for default payment the next month). Exploratory data analysis (EDA) was then conducted to understand the data and highlight connections between various features and the target variable. Noteworthy predictors of default were identified, such as credit limit, payment history, and age.\n",
        "\n",
        "To validate EDA findings, a hypothesis test was conducted. A two-sample z-test for proportions was used to determine if females were more likely than males to miss payments, and a two-sample t-test was employed to assess if the average credit limit for defaulters differed from that of non-defaulters. The results of these tests supported the EDA conclusions.\n",
        "\n",
        "Subsequent to EDA and hypothesis testing, data pre-processing was carried out. This involved handling missing values, removing redundant columns, and selecting features based on low correlation and VIF factor. To address class imbalance in the target variable, the SMOTE approach was applied to oversample the minority class.\n",
        "\n",
        "Several machine learning models, including logistic regression, decision trees, random forests, XGBoost, and K-nearest neighbors, were trained and evaluated using metrics such as recall, accuracy, and F1 scores. Cross-validation and hyperparameter tuning were performed to enhance model performance.\n",
        "\n",
        "The XGBoost model, demonstrating the highest performance, was selected to estimate the likelihood of new credit card users defaulting on their payments.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary objective of this project is to forecast customer default payments in Taiwan. From a risk management standpoint, the predictive accuracy of the estimated probability of default holds greater significance than a binary classification outcome distinguishing between credible and non-credible clients. The K-S chart can be employed to assess and identify customers likely to default on their credit card payments."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries that are used for analysis and visualization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import missingno\n",
        "\n",
        "# libraries to do statistical analysis and tests\n",
        "import scipy\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# libraries for data preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# libraries for performance analysis\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay,roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "\n",
        "# ML model libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# Hypermeter technique libraries\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "\n",
        "# libraries for model interpretation\n",
        "!pip install shap==0.40.0\n",
        "import shap\n",
        "import graphviz\n",
        "\n",
        "import pickle\n",
        "\n",
        "sns.set(style='whitegrid')\n",
        "pd.set_option('display.max_columns', None)\n"
      ],
      "metadata": {
        "id": "HOC9R5OauO5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "my7jaSdqujCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data set\n",
        "Credit_cf = pd.read_excel('/content/drive/MyDrive/default of credit card clients.xls')\n",
        ""
      ],
      "metadata": {
        "id": "YR79e09Tuu0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Credit_cf.head() # Top 5 rows of our dataset.\n",
        ""
      ],
      "metadata": {
        "id": "kaa6LWiCwF0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Credit_cf.tail() # last 5 rows of our data set"
      ],
      "metadata": {
        "id": "3vtAgY3kwLRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "# Check the how many raws and columns in our data set.\n",
        "print(f'Creidt_Card = {Credit_cf.shape[0]} Rows , {Credit_cf.shape[1]} columns.')\n",
        ""
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "Credit_cf.info()\n",
        ""
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Duplicate values\n",
        "Credit_cf.duplicated().sum()\n",
        ""
      ],
      "metadata": {
        "id": "a61p_pePwbpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Missing/null values\n",
        "Credit_cf.isnull().sum().sort_values(ascending = False)"
      ],
      "metadata": {
        "id": "jSTiRpDSwiTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Visualize missing/values\n",
        "import missingno as msno"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using matrix bar chart\n",
        "msno.matrix(Credit_cf)"
      ],
      "metadata": {
        "id": "sA5lCru_wpKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our Credit card default data set have no null Values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "Credit_cf.keys()"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "Credit_cf.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  ID: ID of each client\n",
        "\n",
        "*   LIMIT_BAL: Amount of given credit in NT dollars (includes individual and family/supplementary credit)\n",
        "*   SEX: Gender (1 = male, 2 = female)\n",
        "*   EDUCATION: (1 = graduate school, 2 = university, 3 = high school, 0,4,5,6 = others)\n",
        "\n",
        "*   MARRIAGE: Marital status (0 = others, 1 = married, 2 = single, 3 = others)\n",
        "\n",
        "*   AGE: Age in years\n",
        "\n",
        "*   Scale for PAY_0 to PAY_6 : (-2 = No consumption, -1 = paid in full, 0 = use of revolving credit (paid minimum only), 1 = payment delay for one month, 2 = payment delay for two months, 3 = payment delay for three months,.... 8 = payment delay for eight months, 9 = payment delay for nine months and above)\n",
        "\n",
        "*   PAY_0: Repayment status in September, 2005 (scale same as above)\n",
        "\n",
        "\n",
        "\n",
        "*   PAY_2: Repayment status in August, 2005 (scale same as above)\n",
        "\n",
        "\n",
        "\n",
        "*  PAY_3: Repayment status in July, 2005 (scale same as above)\n",
        "\n",
        "\n",
        "\n",
        "*   PAY_4: Repayment status in June, 2005 (scale same as above)\n",
        "\n",
        "\n",
        "\n",
        "*   PAY_5: Repayment status in May, 2005 (scale same as above)\n",
        "\n",
        "\n",
        "\n",
        "*   PAY_6: Repayment status in April, 2005 (scale same as above)\n",
        "*   BILL_AMT1: Amount of bill statement in September, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*   BILL_AMT2: Amount of bill statement in August, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*   BILL_AMT3: Amount of bill statement in July, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*  BILL_AMT4: Amount of bill statement in June, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*   BILL_AMT5: Amount of bill statement in May, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*   BILL_AMT6: Amount of bill statement in April, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*   PAY_AMT1: Amount of previous payment in September, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*   PAY_AMT2: Amount of previous payment in August, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   PAY_AMT3: Amount of previous payment in July, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   PAY_AMT4: Amount of previous payment in June, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   PAY_AMT5: Amount of previous payment in May, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*  PAY_AMT6: Amount of previous payment in April, 2005 (NT dollar)\n",
        "\n",
        "\n",
        "*  default.payment.next.month: Default payment (1=yes, 0=no)\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in Credit_cf.columns:\n",
        "  if col in []:\n",
        "    continue\n",
        "  else:\n",
        "      print(f'The unique values in column {col} are' ,Credit_cf[col].unique() )"
      ],
      "metadata": {
        "id": "9pA0AMdGyrvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Credit_cf.nunique()"
      ],
      "metadata": {
        "id": "YInlmhNPyvHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Rename some columns for Better Understanding\n",
        "Credit_cf.rename(columns ={'default payment next month' : 'Is_defulter'},inplace = True) # change name defult payment to Is_defuter\n",
        "# name change according to months\n",
        "Credit_cf.rename(columns = {'PAY_0' : 'Pay_sep', 'PAY_2' : 'Pay_aug','PAY_3': 'Pay_jul','PAY_4':'Pay_Jun','PAY_5':'Pay_may' , 'PAY_6': 'Pay_Apr'},inplace = True) # name change according to months\n",
        "# Rename the bill amount\n",
        "Credit_cf.rename(columns = {'BILL_AMT1':'Bill_amt_sept','BILL_AMT2':'Bill_amt_aug','BILL_AMT3':'Bill_amt_jul','BILL_AMT4':'Bill_amt_jun','BILL_AMT5' : 'Bill_amt_may','BILL_AMT6': 'Bill_amt_apr'},inplace = True)\n",
        "# Rename the payment amount\n",
        "Credit_cf.rename(columns={'PAY_AMT1':'Pay_amt_sept','PAY_AMT2':'Pay_amt_aug','PAY_AMT3':'Pay_amt_jul','PAY_AMT4':'Pay_amt_jun','PAY_AMT5':'Pay_amt_may','PAY_AMT6':'PAY_amt_apr'},inplace=True)\n",
        ""
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Education"
      ],
      "metadata": {
        "id": "MHF4vH17zaxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many values in Eduction\n",
        "Credit_cf['EDUCATION'].value_counts()\n",
        ""
      ],
      "metadata": {
        "id": "wplJE8J9zGAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 = graduate school; 2 = university; 3 = high school; 4 = others"
      ],
      "metadata": {
        "id": "Eh4quiY-zTw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fill = (Credit_cf['EDUCATION'] == 5) | (Credit_cf['EDUCATION'] == 6) | (Credit_cf['EDUCATION'] == 0)\n",
        "Credit_cf.loc[fill,'EDUCATION'] = 4\n",
        "Credit_cf['EDUCATION'].value_counts()"
      ],
      "metadata": {
        "id": "D2XK9hqLzLA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the dataset, there are numbers like 5, 6, and 0 for which there is no explanation, thus we can add them together to make 4, or Others.\n",
        "\n",
        "Marriage"
      ],
      "metadata": {
        "id": "enwqHb06zP_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many value in marriage\n",
        "Credit_cf['MARRIAGE'].value_counts()\n",
        ""
      ],
      "metadata": {
        "id": "pq5nyyyhzdPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 = married , 2 = single , 3 = others"
      ],
      "metadata": {
        "id": "yAq5C03Jzhor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M_fill = (Credit_cf['MARRIAGE'] == 0)\n",
        "Credit_cf.loc[M_fill , 'MARRIAGE'] = 3\n",
        "Credit_cf['MARRIAGE'].value_counts()\n",
        ""
      ],
      "metadata": {
        "id": "2v-ld9zdzjfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A couple of the values for 0 are undetermined. I've added them to the Others category."
      ],
      "metadata": {
        "id": "TYRBCwu_zoLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Credit_cf.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "JrgoQkXHzpbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   First we rename column name for understand the all features like default payment next month to Is_defulter, Pay_0 to pay_6 to all the number replace to month like bill amt 1 to bill_amt_6 and pay_amt1 to Pay_6 and these feature also.\n",
        "*   The dataset, there are numbers like 5, 6, and 0 for which there is no explanation, thus we can add them together to make 4, or Others.\n",
        "\n",
        "\n",
        "*   A couple of the values for 0 are undetermined. I've added them to the Others category.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# first bar chart\n",
        "# pie chart\n",
        "# Check how many defaulter and non defaulter.\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,6))\n",
        "ax = Credit_cf['Is_defulter'].value_counts().plot(kind='bar',title=\"Is_defulter\",ax=axes[0])\n",
        "Credit_cf['Is_defulter'].value_counts().plot(kind='pie',title=\"Is_defulter\",autopct='%1.1f%%',ax=axes[1])\n",
        "ax.set_ylabel(\"Count\")\n",
        "ax.set_xlabel(\"Is_defulter\")\n",
        "fig.tight_layout()\n",
        "\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We Pick the countplot because Countplot Shows Number of Dataset."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we clearly see in the Countplot our data is Imbalance Data set.\n",
        "\n",
        "0 is higher then 1"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "Our data set is imbalanced Non defulter user value is high and defulter user value is low ."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many males or females are defaulter and non defaulter\n",
        "plt.figure(figsize=(12,7), dpi=80)\n",
        "Credit_cf['SEX'].value_counts().plot(kind = 'pie',autopct='%1.1f%%',explode = (0.2, 0.0), colors = ['y','red', 'green','orange'],startangle=360,fontsize=14,shadow=True)\n",
        "plt.title(\"Sex\")\n",
        "fig=plt.gcf()\n",
        "plt.legend(loc=\"best\")\n",
        "fig.set_size_inches(6,6)\n",
        "plt.show()\n",
        "Credit_cf.groupby(\"SEX\")[\"Is_defulter\"].sum().plot.pie(title='Sex defaulter', legend=True, autopct='%1.1f%%', labels=['Not Default','Default'], shadow=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pie chart: How many male and female use credit card.\n",
        "\n",
        "Pie Chart: To get proportion of defaults for each sex. 1 = male 2 = female"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are more women than men in our dataset and apparently, men have a slightly higher rate of default compared to female"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "It may not have a significant positive business impact"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using bar chart\n",
        "fig,ax=plt.subplots(figsize=(20,5))\n",
        "sns.barplot(data= Credit_cf , x='SEX' , y = 'Is_defulter' ,hue = 'EDUCATION' , ax=ax , palette = 'pastel')\n",
        "ax.set(title = 'Is Defulter According to Sex and Education')\n",
        "plt.xlabel(\"Education : (1=graduate school, 2=university, 3=high school, 4=others)\")\n",
        "plt.show()\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "YMPA2PV27x9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie Chart: To get proportion of defaults for clients by each education and sex"
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Default rate for High School educated clients is highest and Others category clients has lowest rate of default and High school of females more default than man."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.It will help to gain insight to help creating a positive business impact."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Bar chart\n",
        "fig, axes  = plt.subplots(ncols=2,figsize = (20,6))\n",
        "sns.countplot(x = 'MARRIAGE',ax = axes[0] ,data = Credit_cf)\n",
        "sns.countplot (x ='MARRIAGE',hue = 'Is_defulter',ax= axes [1], data = Credit_cf )\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "drRRzrI-8NQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie Chart: To get proportion of defaults for clients by each marriage."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most people fall under Married and Single category with singles being highest.\n",
        "\n",
        "The default rate in all the categories is almost same with in Others and Married clients"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "Yes.It will help to gain insight to help creating a positive business impact."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "sns.countplot(x = 'AGE', data = Credit_cf,palette= \"Set1\" )"
      ],
      "metadata": {
        "id": "tZQEdJiO8n7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20,5))\n",
        "sns.countplot(x = 'AGE' , hue = 'Is_defulter' , data = Credit_cf , palette = 'pastel')\n",
        ""
      ],
      "metadata": {
        "id": "vxWXMlgp8us8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare customer numbers by age"
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As compared to clients who are between the ages of 23 to 37, users and defrauders are more prevalent between those two ages."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.It will help to gain insight to help creating a positive business impact"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "Credit_cf['LIMIT_BAL'].value_counts()\n",
        ""
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "sns.histplot(x = 'LIMIT_BAL', hue = 'Is_defulter' ,data = Credit_cf, kde = True)\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "u_9XlfOc9agA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram to visualize distribution of LIMIT_BAL."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution is right-skewed, as predicted, and the majority of clients have credit limits of 200k or less, with a higher rate of default in that range."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.It will help to gain insight to help creating a positive business impact."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Pay_col = ['Pay_sep',\t'Pay_aug',\t'Pay_jul','Pay_Jun' , 'Pay_may','Pay_Apr']\n",
        "for col in Pay_col:\n",
        "  plt.figure(figsize = (20,5))\n",
        "  sns.countplot (x = col , hue = 'Is_defulter', data = Credit_cf , palette = 'pastel')\n",
        ""
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plot to plot rate of default for different late payment count."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chances of default rise as the number of late payments rises."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.It will help to gain insight to help creating a positive business impact."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pay_amnt_df = Credit_cf[['Pay_amt_sept','Pay_amt_aug',\t'Pay_amt_jul',\t'Pay_amt_jun', 'Pay_amt_may',\t'PAY_amt_apr','Is_defulter']]\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "8gNYluYSAb2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data = pay_amnt_df, hue ='Is_defulter' )"
      ],
      "metadata": {
        "id": "9-hyD4pS98x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "scatter plot To visualize default rate for different pay amount groups and find any pattern."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As is evident, clients in the orange are defaulter or blue spots are non defaulters and are now being paid for a period of six months."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.It will help to gain insight to help creating a positive business impact."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check correlation between Bill amount\n",
        "Bill_amount = Credit_cf[['Bill_amt_sept',\t'Bill_amt_aug',\t'Bill_amt_jun',\t'Bill_amt_may',\t'Bill_amt_apr']]\n",
        ""
      ],
      "metadata": {
        "id": "ZgUsw9w3-a6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data = Bill_amount)"
      ],
      "metadata": {
        "id": "hDN__Aq1-c75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pair plot show Bill amt of every month"
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative bill statements are associated with a reduced likelihood of default than positive ones, as would be predicted. What is notable is that those who didn't have a bill in the preceding months had a somewhat higher likelihood of defaulting."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.It will help to gain insight to help creating a positive business impact"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('ggplot')\n",
        "plt.figure(figsize=(20,7))\n",
        "plt.title(\"Credit Limit vs Sex\")\n",
        "sns.boxplot(x='SEX',y='LIMIT_BAL',hue='Is_defulter',data=Credit_cf)\n",
        "plt.ylabel(\"Credit Limit\")\n",
        "plt.xlabel('Sex  1:Male   2: Female')\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "jYjMBJZF-ugx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "box plot help me to check the mean vaule so i use the box plot."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Females Credit limit higher level than Men and default value same both of the categories."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.It will help to gain insight to help creating a positive business impact"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('ggplot')\n",
        "plt.figure(figsize=(20,7))\n",
        "plt.title(\"Age vs Marriage\")\n",
        "sns.boxplot(x='Is_defulter',hue='MARRIAGE', y='AGE',data=Credit_cf)\n",
        "plt.ylabel(\"Age\")\n",
        "plt.xlabel('0:Non-Default,1:Default')\n",
        "plt.legend(['Married','Unmarried','Others'])\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "huVDrNJ7_Lw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "box plot help me to check the mean vaule so i use the box plot."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.It will help to gain insight to help creating a positive business impact"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "correlation = Credit_cf.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "obzl00Ex_a7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the correlation between each features in the dataset."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The BILL_AMT columns have a strong correlation, which is understandable given that everyone has similar spending habits. Similarly, there is a correlation between PAY_AMT."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.It will help to gain insight to help creating a positive business impact"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(Credit_cf, vars=Credit_cf.columns[11:17], kind='scatter',hue= 'Is_defulter')\n",
        "sns.pairplot(Credit_cf, vars=Credit_cf.columns[17:23],hue = 'Is_defulter')\n",
        ""
      ],
      "metadata": {
        "id": "fOWnbopx_sg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using pairplot for check tha all variable Outliers."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.It will help to gain insight to help creating a positive business impact\n",
        "\n"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: Maritial Status did not have any affect on default payment.\n",
        "\n",
        "Alternate hypothesis: Maritial Status have affected default payment"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two groups based on sex\n",
        "male_defaults = Credit_cf[( Credit_cf['SEX'] == 1) & ( Credit_cf['Is_defulter'] == 1)]\n",
        "female_defaults =  Credit_cf[( Credit_cf['SEX'] == 2) & ( Credit_cf['Is_defulter'] == 1)]\n",
        "\n",
        "# Calculate the proportions of defaulters in each group\n",
        "male_proportion = len(male_defaults) / len(Credit_cf[Credit_cf['SEX'] == 1])\n",
        "female_proportion = len(female_defaults) / len(Credit_cf[ Credit_cf['SEX'] == 2])\n",
        "\n",
        "# Perform the test for the difference in proportions\n",
        "z_score, p_value = proportions_ztest([len(female_defaults), len(male_defaults)],\n",
        "                                           [len( Credit_cf[ Credit_cf['SEX'] == 2]), len( Credit_cf[ Credit_cf['SEX'] == 1])],\n",
        "                                           alternative='smaller')\n",
        "\n",
        "# Print the results\n",
        "print(\"Male default rate:\", round(male_proportion, 4))\n",
        "print(\"Female default rate:\", round(female_proportion, 4))\n",
        "print(\"Z-score:\", z_score)\n",
        "print(\"P-value:\", p_value)\n",
        "print()\n",
        "if p_value < 0.05:\n",
        "  print(f\"Since p-value ({p_value}) is less than 0.05, we reject null hypothesis.\\nHence, The proportion of defaulters is lower for females than for males.\")\n",
        "else:\n",
        "  print(f\"Since p-value ({p_value}) is greater than 0.05, we fail to reject null hypothesis.\\nHence, The proportion of defaulters is the same for males and females.\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "-7R6VFdPASl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The null hypothesis was rejected, and the proportion of defaulters is smaller for women than for men, according to the one-tailed two-sample z-test I used as the statistical test to get the P-Value."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two-sample z-test for proportions is used to detect whether there is a significant difference between two groups (in this example, males and females) in the proportion of a particular outcome (in this case, default payment). The one-tailed nature of the test implies that the direction of the differencewhether females have a smaller proportion of defaulters than malesrather than the size of the difference is all that is important."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: The average credit limit for defaulters is equal to the average credit limit for non-defaulters.\n",
        "\n",
        "Alternative hypothesis: The average credit limit for defaulters is lower than the average credit limit for non-defaulters.\n",
        "\n",
        "Test Type: Two-sample t-test"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Split the data into defaulters and non-defaulters\n",
        "defaulters = Credit_cf[Credit_cf['Is_defulter'] == 1]\n",
        "non_defaulters = Credit_cf[Credit_cf['Is_defulter'] == 0]\n",
        "\n",
        "# Calculating the mean credit limit for defaulters and non-defaulters\n",
        "mean_credit_limit_defaulters = defaulters['LIMIT_BAL'].mean()\n",
        "mean_credit_limit_non_defaulters = non_defaulters['LIMIT_BAL'].mean()\n",
        "\n",
        "# Calculating the standard deviation of credit limit for defaulters and non-defaulters\n",
        "std_credit_limit_defaulters = defaulters['LIMIT_BAL'].std()\n",
        "std_credit_limit_non_defaulters = non_defaulters['LIMIT_BAL'].std()\n",
        "\n",
        "# Calculate the sample sizes for defaulters and non-defaulters\n",
        "n_defaulters = len(defaulters)\n",
        "n_non_defaulters = len(non_defaulters)\n",
        "\n",
        "# Calculate the standard error of the mean difference\n",
        "se_mean_difference = ((std_credit_limit_defaulters ** 2 / n_defaulters) + (std_credit_limit_non_defaulters ** 2 / n_non_defaulters)) ** 0.5\n",
        "\n",
        "# Calculate the t-statistic and p-value using the two-sample t-test\n",
        "t_stat, p_value = scipy.stats.ttest_ind(defaulters['LIMIT_BAL'], non_defaulters['LIMIT_BAL'], equal_var=False)\n",
        "\n",
        "# Print the results\n",
        "print('Mean credit limit for defaulters:', mean_credit_limit_defaulters)\n",
        "print('Mean credit limit for non-defaulters:', mean_credit_limit_non_defaulters)\n",
        "print('t-statistic:', t_stat)\n",
        "print('p-value:', p_value)\n",
        "print()\n",
        "if p_value < 0.05:\n",
        "  print(f\"Since p-value ({p_value}) is less than 0.05, we reject null hypothesis.\\nHence, The average credit limit for defaulters is lower than the average credit limit for non-defaulters.\")\n",
        "else:\n",
        "  print(f\"Since p-value ({p_value}) is greater than 0.05, we fail to reject null hypothesis.\\nHence, The average credit limit for defaulters is equal to the average credit limit for non-defaulters.\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "znKzfAV5ApiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        ""
      ],
      "metadata": {
        "id": "OxFY46zxAxE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The null hypothesis was rejected, and the average credit limit for defaulters is lower than the average credit limit for non-defaulters, according to the results of my two-sample t-test statistical analysis."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two-sample t-test is a statistical test for comparing means and is useful when the requirements of normality are met, yet we may still apply the t-test if the sample sizes are big (6636 and 23364 in this example)."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Handling Missing Values**"
      ],
      "metadata": {
        "id": "554u7O3mBgeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No Missing value in our data set."
      ],
      "metadata": {
        "id": "pOFVVOfXBibG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Numerical_columns = ['ID', 'LIMIT_BAL', 'AGE', 'Bill_amt_sept',\t'Bill_amt_aug','Bill_amt_jul'\t,'Bill_amt_jun',\t'Bill_amt_may',\t'Bill_amt_apr','Pay_amt_sept','Pay_amt_aug',\t'Pay_amt_jul',\t'Pay_amt_jun', 'Pay_amt_may',\t'PAY_amt_apr']\n",
        ""
      ],
      "metadata": {
        "id": "kyIgMjQyBTi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_histograms(Credit_cf, columns, bins=50):\n",
        "    fig=plt.figure(figsize=(18,25))\n",
        "    for i, col in enumerate(Numerical_columns):\n",
        "      plt.subplot(10, 4, i+1)\n",
        "      sns.histplot(Credit_cf[col], kde=True, bins=bins)\n",
        "      plt.title(col)\n",
        "    fig.tight_layout()\n",
        ""
      ],
      "metadata": {
        "id": "5BIucm_tBV_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_histograms(Credit_cf , Numerical_columns)"
      ],
      "metadata": {
        "id": "9qb51otvBY1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that most of the numerical columns are right skewed.\n",
        "\n",
        "Also late_payment_count have 6 values with 0 being majority and we can't treat high values (5 or 6) as outliers as these high values increases chances of defaulting."
      ],
      "metadata": {
        "id": "T4L0hecXBr34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Looking deep into cases with high values for BILL_AMT1 to study if they are genuine observations of data entry errors\n",
        "Credit_cf[Credit_cf['Bill_amt_sept'] > 400000][['LIMIT_BAL', 'Pay_sep', 'Pay_aug', 'Pay_jul', 'Bill_amt_sept','Bill_amt_aug', 'Bill_amt_jul', 'Pay_amt_sept', 'Pay_amt_aug', 'Pay_amt_jul', 'Is_defulter']].head(20)\n",
        ""
      ],
      "metadata": {
        "id": "k4EJ91sDBtnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "They looks like rows with very high values for BILL_AMTX also their LIMIT_BAL is very high. So they must be representing few super rich people and the data are genuine not an error. Hence they are not outliers.\n",
        "\n",
        "Those who defaulted have significantly lower PAY_AMT compared to BILL_AMT which is expected."
      ],
      "metadata": {
        "id": "JYwE_5RjByo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Credit_cf[Credit_cf['Bill_amt_sept'] > 300000][['LIMIT_BAL', 'Pay_sep', 'Pay_aug', 'Pay_jul', 'Bill_amt_sept','Bill_amt_aug', 'Bill_amt_jul', 'Pay_amt_sept', 'Pay_amt_aug', 'Pay_amt_jul', 'Is_defulter']].head(20)\n",
        "\n"
      ],
      "metadata": {
        "id": "ttrpJmbQB1T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly for very high PAY_AMT values we can see they have very high BILL_AMT in previous months and all payments are done duly, So they must be representing super rich people and data is genuine and not errors. Hence they are not outliers."
      ],
      "metadata": {
        "id": "hKJOsU9gB588"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no outliers."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Credit_cf.replace({'SEX': {1 : 'MALE', 2 : 'FEMALE'}, 'EDUCATION' : {1 : 'graduate school', 2 : 'university', 3 : 'high school', 4 : 'others'}, 'MARRIAGE' : {1 : 'married', 2 : 'single', 3 : 'others'}}, inplace = True)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "MllU_frvCBPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Credit_cf['EDUCATION']"
      ],
      "metadata": {
        "id": "-k55fDkvCDsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Credit_cf"
      ],
      "metadata": {
        "id": "8wX9nmM4CGW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One Hot encoding**\n",
        "\n"
      ],
      "metadata": {
        "id": "MELhlb5ZCQZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dumification of Education and marriage variable's\n",
        "Credit_cf = pd.get_dummies(Credit_cf,columns=['EDUCATION','MARRIAGE'])\n",
        ""
      ],
      "metadata": {
        "id": "td3CO8njCmcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Credit_cf.head()"
      ],
      "metadata": {
        "id": "60aAlQh_CpBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the Education others and marriage others variable's\n",
        "Credit_cf.drop(['EDUCATION_others','MARRIAGE_others'],axis = 1, inplace = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "awQtkHvPCsC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do dummification of payment variables\n",
        "Credit_cf = pd.get_dummies(Credit_cf, columns = ['Pay_sep',\t'Pay_aug',\t'Pay_jul','Pay_Jun' , 'Pay_may','Pay_Apr'], drop_first = True )\n",
        ""
      ],
      "metadata": {
        "id": "Ek6YmQFiCuwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Credit_cf.head()"
      ],
      "metadata": {
        "id": "Bo8tnmv1CxRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LABEL ENCODING FOR SEX\n",
        "encoders_nums = {\n",
        "                 \"SEX\":{\"FEMALE\": 0, \"MALE\": 1}\n",
        "}\n",
        "Credit_cf = Credit_cf.replace(encoders_nums)\n",
        "\n"
      ],
      "metadata": {
        "id": "_HJq7J_pC1Tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Credit_cf.head()"
      ],
      "metadata": {
        "id": "ZttoblBkC3ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Credit_cf.shape"
      ],
      "metadata": {
        "id": "FGu-g3HCC6qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have use one hot cording sex , Education ,marriage and pay because the represents categorical values with no order also number of categories is not too high."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,11))\n",
        "sns.heatmap(abs(Credit_cf[Numerical_columns].corr()), annot = True, cmap = 'cool').set_title('Correlation Heatmap to analyze the features', fontsize = 18)\n",
        "plt.show\n",
        ""
      ],
      "metadata": {
        "id": "OTP5L70mDRC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        "  vif = pd.DataFrame()\n",
        "  vif[\"variable\"] = X.columns\n",
        "  vif[\"VIF\"] = [variance_inflation_factor(X.values ,i) for i in range (X.shape[1])]\n",
        "\n",
        "  return(vif)\n",
        "\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(Credit_cf[Numerical_columns])"
      ],
      "metadata": {
        "id": "rnO06-AdDXqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(Credit_cf[[i for i in(Credit_cf[Numerical_columns]).describe().columns if i not in ['Bill_amt_sept',\t'Bill_amt_aug',\t'Bill_amt_jun',\t'Bill_amt_may',\t'Bill_amt_apr']]])\n",
        "\n"
      ],
      "metadata": {
        "id": "6mHLgnEbDbCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Cr = Credit_cf.drop('ID',axis = 1)"
      ],
      "metadata": {
        "id": "WgLhJmBRDdy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Cr"
      ],
      "metadata": {
        "id": "hd-M2eX6Df5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there are only 9 categorical features, I have used only One Hot Encoding. One Hot Encoding creates new columns as much as the number of unique values. One Hot Encoding makes our training data more useful and expressive, and it can be rescaled easily."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = Cr.drop('Is_defulter', axis=1)\n",
        "y = Cr['Is_defulter']"
      ],
      "metadata": {
        "id": "cX9N2pa2Dq5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split the Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "KIpZCxQ9DtaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that the data is unbalanced from the above.\n",
        "\n",
        "\n",
        "\n",
        "*   Only 22% of the data in our 24,000 training sample are defaults.\n",
        "\n",
        "*  \n",
        "Only 21.6% of the 6000 test dataset's data are defaults.\n",
        "\n",
        "\n",
        "\n",
        "Therefore, we must balance the datasets we use for training and testing."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upsamping minority class using SMOTE method\n",
        "print(\"Before oversampling: \",Counter(y_train))\n",
        "SMOTE= SMOTE()\n",
        "# Resampling the minority class\n",
        "X_train,y_train= SMOTE.fit_resample(X_train,y_train)\n",
        "print(\"After oversampling: \",Counter(y_train))\n",
        ""
      ],
      "metadata": {
        "id": "w2uk_OfQEGfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Handling Imbalanced Dataset (If needed)\n",
        "print(\"Before oversampling: \",Counter(y_test))\n",
        "\n",
        "X_test,y_test= SMOTE.fit_resample(X_test,y_test)\n",
        "print(\"After oversampling: \",Counter(y_test))"
      ],
      "metadata": {
        "id": "ivw7TWNdEJVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because undersampling might result in data loss, I have not employed it. This would result in the loss of around 13,000 rows from our training dataset.\n",
        "\n",
        "To balance our data, I have instead employed Synthetic Minority Oversampling Technique (SMOTE). This method produces fake data for the minority class. SMOTE operates by selecting a point at random from the minority class and calculating its k-nearest neighbors. Between the selected point and its neighbors, the synthetic points are inserted."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Data Scaling**"
      ],
      "metadata": {
        "id": "ZwiUzVnpERa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "lbscFd4BEZ6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "std = StandardScaler()\n",
        "X_train= std.fit_transform(X_train)\n",
        "X_test = std.fit_transform(X_test)\n"
      ],
      "metadata": {
        "id": "KiNBQR8bEdWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which method have you used to scale you data and why?**"
      ],
      "metadata": {
        "id": "uyN1Z3ncEh5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The process used to normalize the variety of characteristics in data is known as feature scaling, often referred to as data normalization. Since data values might fluctuate considerably, preparing the data before utilizing machine learning algorithms becomes essential.\n",
        "\n",
        "Standardization and Normalization\n",
        "\n",
        "Normalization is the process of transforming your observations into something that can be compared to a normal distribution. Your data are transformed by standardization, also known as z-score normalization, to produce a distribution with a mean of 0 and a standard deviation of 1."
      ],
      "metadata": {
        "id": "Any0p9WPEmwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Dimesionality Reduction**"
      ],
      "metadata": {
        "id": "XQaXqyg_Epe4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "Suy8VKOhEsSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ns_vCeRhEvyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "RZVPizGFEyud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)**\n"
      ],
      "metadata": {
        "id": "NvnLFjTvE3Mk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "dRpo816fE5Bh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "log = LogisticRegression(random_state = 42)\n",
        "\n",
        "# Fit the Algorithm\n",
        "log.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org."
      ],
      "metadata": {
        "id": "W5DbMXh_FJRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "log_train  = log.predict(X_train)\n",
        "log_test  = log.predict(X_test)"
      ],
      "metadata": {
        "id": "nuCAoGtgFOAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "train_accuracy = accuracy_score(log_train,y_train)\n",
        "test_accuracy = accuracy_score(log_test,y_test)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['NO-DEFAULT', 'DEFAULT']\n",
        "cm = confusion_matrix(y_train, log_train)\n",
        "print(cm)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix of Training Data')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "emq9SCZTFVzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['NO-DEFAULT', 'DEFAULT']\n",
        "cm = confusion_matrix(y_test, log_test)\n",
        "print(cm)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix of Test Data')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "ExfRCmAHFZKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.**"
      ],
      "metadata": {
        "id": "PDyG-RrBFfWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression was utilized. It's a classification method that forecasts the likelihood of a result that can only take one of two possible forms (i.e., dichotomy). It generates a logistic curve with a range of 0 to 1 values only."
      ],
      "metadata": {
        "id": "au_IjX92FhmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,log_test))"
      ],
      "metadata": {
        "id": "lQKCDXNgFjvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import cross_validate\n",
        ""
      ],
      "metadata": {
        "id": "yh-Z5YAsFpxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_grid = {'penalty':['l1','l2'], 'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
        "# searching the best parameter\n",
        "grid_lr_clf = GridSearchCV(LogisticRegression(), param_grid, scoring = 'accuracy', n_jobs = -1, verbose = 3, cv = 3)\n",
        "# Fit the Algorithm\n",
        "grid_lr_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org."
      ],
      "metadata": {
        "id": "JDRVhMhlFzw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best parameter\n",
        "print(\"The best parameters is found out to be :\" ,grid_lr_clf.best_params_)\n",
        "print(\"\\nUsing \",grid_lr_clf.best_params_, \" the recall score is: \", grid_lr_clf.best_score_)\n",
        ""
      ],
      "metadata": {
        "id": "fMSGLyZJF2sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take best parmeter and fit x train and y train\n",
        "logit = LogisticRegression(C=0.01, fit_intercept=False, penalty='l2')\n",
        "logit.fit(X_train, y_train)\n",
        ""
      ],
      "metadata": {
        "id": "IqyQeqdkF6v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org."
      ],
      "metadata": {
        "id": "KauBvvQlF-tI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the values\n",
        "train_log_hp = logit.predict(X_train)\n",
        "test_log_hp = logit.predict(X_test)"
      ],
      "metadata": {
        "id": "MS4O1z3SGBnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check the accurracy of  of predict model\n",
        "train_accuracy2 = accuracy_score(train_log_hp,y_train)\n",
        "test_accuracy2 = accuracy_score(test_log_hp,y_test)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy2)\n",
        "print(\"The accuracy on test data is \", test_accuracy2)\n",
        ""
      ],
      "metadata": {
        "id": "MAm9kdNfGEiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check recall score\n",
        "print(classification_report(y_test,test_log_hp))"
      ],
      "metadata": {
        "id": "SiO7ewO8GHWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC AUC CURVE\n",
        "fpr, tpr, _ = roc_curve(y_test,test_log_hp)\n",
        "auc = roc_auc_score(y_test,test_log_hp )\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Igk7pyZ5GKoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Logistic regression algorithm to create the model. As I got not so good result.\n",
        "\n",
        "The precision, recall, F1 and roc auc score on test data are: 0.88, 0.76 and 0.81"
      ],
      "metadata": {
        "id": "oBb4hujeGORk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used GridSearchCV to obtain the best parameters to improve upon my Logistic Regression Model. GridSearchCV which uses the gridSearch technique for finding the optimal hyperparameters to increase the model performance.\n",
        "\n",
        "GridSearchCV is a technique to search through the best parameter values from the given set of the grid of parameters."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   There is no increment in accuracy score after using hyperparameter tuning.\n",
        "*   The recall score has increased by 2% after using hyperparameter tuning.\n",
        "\n"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model-2 Implementation\n",
        "clf_dt = DecisionTreeClassifier(criterion='gini', random_state=0, max_leaf_nodes=10)\n",
        "\n",
        "# Fit the Algorithm\n",
        "clf_dt.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "2dFtbsgAGuPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org."
      ],
      "metadata": {
        "id": "zRYropOXGyia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the model\n",
        "train_dt = clf_dt.predict(X_train)\n",
        "test_dt = clf_dt.predict (X_test)"
      ],
      "metadata": {
        "id": "M7_MxsEYG07V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check accuracy of our model\n",
        "train_dt_acc = accuracy_score(train_dt,y_train)\n",
        "test_dt_acc = accuracy_score(test_dt,y_test)\n",
        "print('The accuracy of model train data set is',train_dt_acc)\n",
        "print('The accuracy of model test data set is ',test_dt_acc)\n",
        ""
      ],
      "metadata": {
        "id": "qFmgN5nvG3e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Auc_roc score\n",
        "fpr, tpr, _ = roc_curve(y_test,test_dt)\n",
        "auc = roc_auc_score(y_test,test_dt)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jZTQO5GNG8uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Classifier is the second model I've employed. The most important variable and its value that produces the finest homogenous groupings of population are identified via the decision tree."
      ],
      "metadata": {
        "id": "iyah4XlYGodH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check recall score of test date set\n",
        "print(classification_report(y_test,test_dt))"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques ( GridSearch CV)\n",
        "# giving parameters\n",
        "dt_param = {'criterion':['gini','entropy','log_loss'], 'max_depth': np.arange(3, 15)}\n",
        "\n",
        "dt_grid = GridSearchCV(DecisionTreeClassifier(), param_grid = dt_param, cv=10, verbose=2, scoring='recall')\n",
        "\n",
        "# Fit the Algorithm\n",
        "dt_grid.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check best parameter\n",
        "print(\"The best parameters is found out to be :\" ,dt_grid.best_params_)\n",
        "print(\"\\nUsing \",dt_grid.best_params_, \" the recall score is: \", dt_grid.best_score_)\n",
        ""
      ],
      "metadata": {
        "id": "DlXruCMWHQ-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take the best parmeter\n",
        "dt_tree_grid = DecisionTreeClassifier(criterion='gini', max_depth=13)\n",
        "dt_tree_grid.fit(X_train,y_train)\n",
        ""
      ],
      "metadata": {
        "id": "bteIVkfBHTN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org."
      ],
      "metadata": {
        "id": "mzm2lAb1HVeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict model\n",
        "dt_train_grid = dt_tree_grid.predict(X_train)\n",
        "dt_test_grid = dt_tree_grid.predict(X_test)\n",
        ""
      ],
      "metadata": {
        "id": "hUthbjjvHX6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check accuracy of our model\n",
        "dt_train_grid_acc = accuracy_score(dt_train_grid,y_train)\n",
        "dt_test_grid_acc = accuracy_score(dt_test_grid,y_test)\n",
        "print('The accuracy of modl of hyperparmeter training is ', dt_train_grid_acc)\n",
        "print('The acccuracy of modal of hyperparmeter test is ',dt_test_grid_acc)\n",
        ""
      ],
      "metadata": {
        "id": "jofpq31CHaJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check metrix analysis by heatmap\n",
        "labels = ['NO-DEFAULT', 'DEFAULT']\n",
        "cm = confusion_matrix(y_train,dt_train_grid)\n",
        "print(cm)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix of Training Data')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "ciuSXr4yHdS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['NO-DEFAULT', 'DEFAULT']\n",
        "cm = confusion_matrix(y_test,dt_test_grid)\n",
        "print(cm)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix of Test Data')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        ""
      ],
      "metadata": {
        "id": "dGUop8uuHgDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check evaluation matrix score\n",
        "print(classification_report(y_test,test_dt))\n",
        ""
      ],
      "metadata": {
        "id": "BfGuv_uoHixR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check auc_roc curve by graph\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test,dt_test_grid)\n",
        "auc = metrics.roc_auc_score(y_test,dt_test_grid)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HSm8BSahHknp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explain the ML Model used and it's performance**"
      ],
      "metadata": {
        "id": "zBCYMvyrHndM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used decision tree Classifier algorithm to create the model. As I got not so good result similar to Logistic Regression.\n",
        "\n",
        "The precision, recall, F1 and roc auc score on test data are: 0.83, 0.68, 0.74 and 0.77"
      ],
      "metadata": {
        "id": "cqkAX5vEHrXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV which uses the gridSearch technique for finding the optimal hyperparameters to increase the model performance.\n",
        "\n",
        "GridSearchCV is a technique to search through the best parameter values from the given set of the grid of parameters."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The third model I used was Random Forest. Random Forest develops several trees in contrast to the CART model's one tree. We build trees from the subsets of the original dataset. These subsets could only include some of the columns and rows. We say that a tree \"votes\" for a class when it offers a classification to classify a new object based on features. Regression uses a forest to pick the classification that obtained the most votes (out of all the trees in the forest) by averaging the results from numerous trees."
      ],
      "metadata": {
        "id": "ybJurErtID2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_clf = RandomForestClassifier()\n",
        "rf_clf.fit(X_train , y_train)\n",
        ""
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
        "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org."
      ],
      "metadata": {
        "id": "rrzNJxKgIL3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_rf = rf_clf.predict(X_train)\n",
        "test_rf  = rf_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "jWUhf4zAINPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy_rf = accuracy_score(train_rf, y_train)\n",
        "test_accuracy_rf = accuracy_score(test_rf, y_test)\n",
        "print(\"The accuracy on train data is \", train_accuracy_rf)\n",
        "print(\"The accuracy on test data is \", test_accuracy_rf)\n",
        ""
      ],
      "metadata": {
        "id": "CVmFEIYHIQvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['NO-DEFAULT', 'DEFAULT']\n",
        "cm = confusion_matrix(y_train, train_rf)\n",
        "print(cm)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix of Training Data')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        ""
      ],
      "metadata": {
        "id": "W4mugrEnISy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['NO-DEFAULT', 'DEFAULT']\n",
        "cm = confusion_matrix(y_test,test_rf)\n",
        "print(cm)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix of Test Data')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        ""
      ],
      "metadata": {
        "id": "ypTPHbzgIVIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,test_rf))\n",
        ""
      ],
      "metadata": {
        "id": "mBWjhWWTIXcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, _ = roc_curve(y_test,test_rf)\n",
        "auc = roc_auc_score(y_test,test_rf)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vAqb1E3_Iam9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_grid = {'criterion':['gini','entropy','log_loss'],'n_estimators': [5,10], 'max_depth': [3,15]}\n",
        "# Fit the Algorithm\n",
        "grid_rf_clf = GridSearchCV(RandomForestClassifier(), param_grid, scoring = 'accuracy', n_jobs = -1, verbose = 3, cv = 3)\n",
        "grid_rf_clf.fit(X_train , y_train)\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the best parmeter\n",
        "print(\"The best parameters is found out to be :\" ,grid_rf_clf)\n",
        "print(\"\\nUsing \",grid_rf_clf.best_params_, \" the recall score is: \", grid_rf_clf.best_score_)\n",
        ""
      ],
      "metadata": {
        "id": "wRbnJq4oI_SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run model with best best parmeter\n",
        "rf_grid_clf = RandomForestClassifier(criterion='gini', max_depth=15, n_estimators=10)\n",
        "rf_grid_clf.fit(X_train, y_train)\n",
        ""
      ],
      "metadata": {
        "id": "bmM0eIZrJBGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict model\n",
        "train_rf_grid = rf_grid_clf.predict(X_train)\n",
        "test_rf_grid = rf_grid_clf.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "o9Q4C-SZJDrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the accuracy of our test model\n",
        "train_rf_clf= accuracy_score(train_rf_grid, y_train)\n",
        "test_rf_clf = accuracy_score(test_rf_grid, y_test)\n",
        "print('The accuracy of train set is ',train_rf_clf)\n",
        "print('The accuracy of test set is ',test_rf_clf)\n",
        ""
      ],
      "metadata": {
        "id": "u_2ZAFXDJF5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training confusion matrix\n",
        "labels = ['NO-DEFAULT', 'DEFAULT']\n",
        "cm = confusion_matrix(y_train,train_rf_grid)\n",
        "print(cm)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix of Training Data')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "FtPU6titJIKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Confusion Matrix\n",
        "labels = ['NO-DEFAULT', 'DEFAULT']\n",
        "cm = confusion_matrix(y_test,test_rf_grid)\n",
        "print(cm)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix of Test Data')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        ""
      ],
      "metadata": {
        "id": "bujNz7OCJLAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the matrix score\n",
        "print(classification_report(y_test,test_rf_grid))\n",
        ""
      ],
      "metadata": {
        "id": "ktsxM8rRJNcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the auc_roc curve\n",
        "fpr, tpr, _ = roc_curve(y_test,test_rf_grid)\n",
        "auc = roc_auc_score(y_test,test_rf_grid )\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7zQwwITPJPOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV which uses the gridSearch technique for finding the optimal hyperparameters to increase the model performance.\n",
        "\n",
        "GridSearchCV is a technique to search through the best parameter values from the given set of the grid of parameters"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Random Forest Classifier algorithm to create the model. As I got not so good result similar to Logistic Regression.\n",
        "\n",
        "The precision, recall, F1 and roc auc score on test data are: 0.80, 0.81, 0.80 and 0.80"
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Model - 4 XGBoost**"
      ],
      "metadata": {
        "id": "mNHurAi2J0qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        ""
      ],
      "metadata": {
        "id": "BODjOObwJ5qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtrain=xgb.DMatrix(X_train,label=y_train)\n",
        "dtest=xgb.DMatrix(X_test)"
      ],
      "metadata": {
        "id": "wzITNTBdJ8eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# giving parameters for xgboost\n",
        "parameters={'max_depth':7, 'eta':1, 'silent':1,'objective':'binary:logistic','eval_metric':'auc','learning_rate':.05}\n",
        ""
      ],
      "metadata": {
        "id": "pHoHF8ahJ-tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training our model\n",
        "num_round=50\n",
        "from datetime import datetime\n",
        "start = datetime.now()\n",
        "xg=xgb.train(parameters,dtrain,num_round)\n",
        "stop = datetime.now()"
      ],
      "metadata": {
        "id": "yRRoOUq-KBPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execution time of the model\n",
        "execution_time_xgb = stop-start\n",
        "execution_time_xgb\n",
        ""
      ],
      "metadata": {
        "id": "MHZA7RGWKDk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now predicting our model on train set\n",
        "train_class_preds_probs=xg.predict(dtrain)\n",
        "#now predicting our model on test set\n",
        "test_class_preds_probs =xg.predict(dtest)\n",
        ""
      ],
      "metadata": {
        "id": "CJif31M6KGBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_class_preds_probs)"
      ],
      "metadata": {
        "id": "yabkM6B6KJXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_class_preds = []\n",
        "test_class_preds = []\n",
        "for i in range(0,len(train_class_preds_probs)):\n",
        "  if train_class_preds_probs[i] >= 0.5:\n",
        "    train_class_preds.append(1)\n",
        "  else:\n",
        "    train_class_preds.append(0)\n",
        "\n",
        "for i in range(0,len(test_class_preds_probs)):\n",
        "  if test_class_preds_probs[i] >= 0.5:\n",
        "    test_class_preds.append(1)\n",
        "  else:\n",
        "    test_class_preds.append(0)\n",
        ""
      ],
      "metadata": {
        "id": "JHuBM5iCKMFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_class_preds_probs[:20]"
      ],
      "metadata": {
        "id": "m6ELC90_KO4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check accuracy of train or test model\n",
        "train_accuracy_xgb = accuracy_score(train_class_preds,y_train)\n",
        "test_accuracy_xgb = accuracy_score(test_class_preds,y_test)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_xgb)\n",
        "print(\"The accuracy on test data is \", test_accuracy_xgb)"
      ],
      "metadata": {
        "id": "YWSC528ZKRhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the matrix score\n",
        "print(classification_report(y_test,test_class_preds ))"
      ],
      "metadata": {
        "id": "BfJEr8-lKUFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the auc and roc curve\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test,test_class_preds)\n",
        "auc = metrics.roc_auc_score(y_test,test_class_preds)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "Z9s_95dnKWrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Cross- Validation & Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "IqsoWIdkKaCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques ( GridSearch CV)\n",
        "param_test1 = {\n",
        " 'max_depth':range(3,10,2),\n",
        " 'min_child_weight':range(1,6,2)\n",
        "}\n",
        "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
        " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, # Fit the Algorithm\n",
        " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27),\n",
        " param_grid = param_test1, scoring='accuracy',n_jobs=-1,cv=3, verbose = 2)\n",
        "gsearch1.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        ""
      ],
      "metadata": {
        "id": "54c8sZVjKc4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the best of xgb boost score\n",
        "gsearch1.best_score_"
      ],
      "metadata": {
        "id": "E-dXQy3-Kfyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run with best estimator\n",
        "optimal_xgb = gsearch1.best_estimator_\n",
        ""
      ],
      "metadata": {
        "id": "F8Rar1kyKh8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "train_class_pred = optimal_xgb.predict(X_train)\n",
        "test_class_pred = optimal_xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "2emE6wR4KkZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check accuracy score\n",
        "train_accuracy_xgb_tuned = accuracy_score(train_class_pred,y_train)\n",
        "test_accuracy_xgb_tuned = accuracy_score(test_class_pred,y_test)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy_xgb_tuned)\n",
        "print(\"The accuracy on test data is \", test_accuracy_xgb_tuned)"
      ],
      "metadata": {
        "id": "-xdWjqCEKmtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Confusion matrix\n",
        "labels = ['NO-DEFAULT', 'DEFAULT']\n",
        "cm = confusion_matrix(y_train,train_class_pred)\n",
        "print(cm)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix of Training Data')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)\n",
        ""
      ],
      "metadata": {
        "id": "_osVnTWuKo1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing confusion matrix\n",
        "labels = ['NO-DEFAULT', 'DEFAULT']\n",
        "cm = confusion_matrix(y_test,test_class_pred)\n",
        "print(cm)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix of test Data')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "MnI-aCqRKty7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,test_class_pred))"
      ],
      "metadata": {
        "id": "HIlkNr9GKwou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr,_ = metrics.roc_curve(y_test,test_class_pred)\n",
        "auc = metrics.roc_auc_score(y_test,test_class_pred)\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-YIw5N_PKyi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used XGBoost Classifier algorithm to create the model. As I got notso good result.\n",
        "\n",
        "The precision, recall, F1 and roc auc score on test data are: 0.80, 0.84, 0.82 and 0.81"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV which uses the gridSearch technique for finding the optimal hyperparameters to increase the model performance.\n",
        "\n",
        "GridSearchCV is a technique to search through the best parameter values from the given set of the grid of parameters."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ml Model - 5 K-Nearest neighbor**"
      ],
      "metadata": {
        "id": "z6tzvclFLYlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        ""
      ],
      "metadata": {
        "id": "KrYu8_ECLcoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the parameter\n",
        "param_grid = {'n_neighbors' : [3,4]}\n",
        "knn = GridSearchCV(KNeighborsClassifier(), param_grid, n_jobs = -1, verbose = 3, cv = 4)\n",
        "#training model\n",
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "cQVCVSb7LfF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# best parameter\n",
        "knn.best_params_"
      ],
      "metadata": {
        "id": "6Vx7rsmQLhoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict tha model\n",
        "y_pred_knn_train = knn.predict(X_train)\n",
        "y_pred_knn_test = knn.predict(X_test)\n",
        ""
      ],
      "metadata": {
        "id": "WPQ-7L3YLjwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check accuracy of model\n",
        "train_accuracy_knn = accuracy_score(y_pred_knn_train,y_train)\n",
        "test_accuracy_knn = accuracy_score(y_pred_knn_test,y_test)\n",
        "\n",
        "print(\"The accuracy on train data is \",train_accuracy_knn)\n",
        "print(\"The accuracy on test data is \",test_accuracy_knn)"
      ],
      "metadata": {
        "id": "7W7MsCgcLl7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check matrix score\n",
        "print(classification_report(y_test,y_pred_knn_test))"
      ],
      "metadata": {
        "id": "6jNavR82LoQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check roc_auc curve\n",
        "fpr, tpr,_ =metrics.roc_curve(y_test,y_pred_knn_test)\n",
        "auc = metrics.roc_auc_score(y_test,y_pred_knn_test )\n",
        "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "jlVHkmDwLqSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used K nearest neighbors Classifier algorithm to create the model. As I got not so good result similar to Logistic Regression.\n",
        "\n",
        "The precision, recall, F1 and roc auc score on test data are: 0.88, 0.72, 0.79 and 0.89"
      ],
      "metadata": {
        "id": "BznI1aPYLtAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which hyperparameter optimization technique have you used and why?**"
      ],
      "metadata": {
        "id": "Y2SCnvBrL4oe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV which uses the gridSearch technique for finding the optimal hyperparameters to increase the model performance.\n",
        "\n",
        "GridSearchCV is a technique to search through the best parameter values from the given set of the grid of parameters."
      ],
      "metadata": {
        "id": "dInvYyvoL8Iu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "pnibYk88L-zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The different assessment metrics for categorization issues include:\n",
        "\n",
        "\n",
        "\n",
        "*   Accuracy - Accuracy is simply the proportion of accurately predicted events. Accuracy performs a decent job of balancing specificity and sensitivity, recall and precision, as long as classes are roughly balanced (equal numbers of dog and not-dog photos in the prior example).\n",
        "*   Confusion Matrix: The Confusion Matrix is a performance measurement for classification problems in machine learning in which there can be two or more classes output. It is a table with actual and predicted value combinations. The table that is frequently used to describe the performance of a classification model on a set of test data for which the true values are known is referred to as a confusion matrix. It is extremely helpful for determining the AUC-ROC curves, precision, recall, and accuracy.\n",
        "\n",
        "*   Recall /senstivity :True Positive Rate is another name for recall and sensitivity. It is the percentage of genuine \"YES\" votes that were placed in the appropriate bin. In essence, this provides sensitivity/recall/TPR a very particular use case: utilize it when each instance of what you're seeking for is too valuable to let go.\n",
        "*   Precision: What percentage of the things the model flagged as YES are actually correct?\n",
        "\n",
        "*   F1-Score - F1 score is the harmonic average of recall and precision, taking values between 0 and 1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sWifWYR2MCPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "jmsTnQ6QMrO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The XGB boost model seems to be the best choice for this dataset as it has the highest score in all the metrics (Accuracy, Precision, Recall, F1 and AUC). As shown in figure table:"
      ],
      "metadata": {
        "id": "bdqFRYedMutL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Logistic':78, 'LogisticGSCV': 76,\n",
        "                'Decision_Tree':68, 'Decision_TreeGSCV':68,\n",
        "               'Random_Forest': 81, 'Random_ForestGSCV': 81,\n",
        "                'XGBoost': 82 , 'XGBoostGCV':84 , 'KnnGCV': 72}\n",
        "courses = list(data.keys())\n",
        "values = list(data.values())\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title('Comparing Recall of ML Models',fontsize=20)\n",
        "colors=['red','blue','grey','green','black']\n",
        "plt.bar(courses, values, color =colors,alpha=0.5,width = 0.4)\n",
        "plt.xticks(rotation = 45)\n",
        ""
      ],
      "metadata": {
        "id": "LfLV3DrMM1Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given that the XGBoost model gets the greatest scores across all criteria (Accuracy, Precision, Recall, F1, and AUC), it appears to be the best option for this dataset. According to the figure table"
      ],
      "metadata": {
        "id": "PVPAXFDeM5_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "IrPBrhrcM8a4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The total significance of each feature in a machine learning model is displayed in a SHAP summary graphic. It may be used to determine the key characteristics that are impacting the model's predictions and to learn more about those characteristics.\n",
        "\n",
        "We can observe that the two most crucial features to forecast default are Pay_sept and Marriage."
      ],
      "metadata": {
        "id": "R-oELaJUNuGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment, our task was to classify and predict whether a credit card customer is likely to experience payment delays. For credit card companies, this is of paramount importance as it empowers them to identify high-risk borrowers and implement necessary measures to mitigate potential losses.\n",
        "\n",
        "Within the dataset, approximately 22% are defaulters, while 78% are non-defaulters. Men exhibit a slightly higher frequency of default compared to women. Both younger and older customers have higher default rates. The default rate correlates with increased credit usage, and the likelihood of default rises with the number of late payments. Customers who haven't made any payments in previous months also have a higher default rate.\n",
        "\n",
        "To address data imbalances, Synthetic Minority Over-sampling Technique (SMOTE) was applied during data preparation. The XGBoost model outperformed others in forecasting customer default, achieving maximum accuracy (0.95), recall (0.84), F1 score (0.82), and area under the curve (AUC) (0.81).\n",
        "\n",
        "A feature significance analysis using SHAP values identified PAY_1, Marriage, Education, and other factors as the most crucial for forecasting customer default."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}